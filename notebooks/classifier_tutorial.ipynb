{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JapaneseTextClassifier Tutorial\n",
        "\n",
        "This notebook demonstrates the **JapaneseTextClassifier** - an end-to-end solution for Japanese text classification with built-in LIME explanations.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **Simple API**: Train, predict, and explain in just a few lines of code\n",
        "- **Built-in tokenization**: Automatic Japanese tokenization with Sudachi\n",
        "- **LIME explanations**: Human-readable explanations in Japanese and English\n",
        "- **Model persistence**: Save and load trained models\n",
        "- **FastAPI ready**: Results are JSON-serializable for web APIs\n",
        "\n",
        "## Contents\n",
        "\n",
        "1. [Quick Start](#1-quick-start)\n",
        "2. [Training a Classifier](#2-training-a-classifier)\n",
        "3. [Making Predictions with Explanations](#3-making-predictions-with-explanations)\n",
        "4. [Saving and Loading Models](#4-saving-and-loading-models)\n",
        "5. [API Integration (FastAPI/htmx)](#5-api-integration-fastapihtmx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Quick Start\n",
        "\n",
        "Here's the simplest way to use JapaneseTextClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once)\n",
        "# !pip install sudachipy sudachidict_core pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from tokusan import JapaneseTextClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('fakenews.csv')\n",
        "df = df[df['isfake'].isin([0, 2])].copy()\n",
        "df['label'] = (df['isfake'] == 2).astype(int)\n",
        "\n",
        "# Create and train classifier\n",
        "clf = JapaneseTextClassifier(class_names=['Real', 'Fake'])\n",
        "result = clf.train(df['context'], df['label'])\n",
        "\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict with explanation\n",
        "text = \"これは信頼できるニュース記事です。正確な情報が報道されています。\"\n",
        "pred = clf.predict(text, explain=True)\n",
        "\n",
        "print(pred.summary_jp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training a Classifier\n",
        "\n",
        "Let's look at training in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from tokusan import JapaneseTextClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load and prepare dataset\n",
        "df = pd.read_csv('fakenews.csv')\n",
        "df = df.dropna(subset=['context', 'isfake'])\n",
        "\n",
        "# Filter to binary classification (0=real, 2=fake)\n",
        "df = df[df['isfake'].isin([0, 2])].copy()\n",
        "df['label'] = (df['isfake'] == 2).astype(int)\n",
        "\n",
        "print(f\"Dataset size: {len(df)}\")\n",
        "print(f\"Label distribution:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create classifier with custom settings\n",
        "clf = JapaneseTextClassifier(\n",
        "    class_names=['Real', 'Fake'],       # Class names (index 0, 1)\n",
        "    classifier_type='logistic_regression',  # or 'random_forest'\n",
        "    max_features=20000,                 # TF-IDF vocabulary size\n",
        "    random_state=42                     # For reproducibility\n",
        ")\n",
        "\n",
        "print(clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "result = clf.train(\n",
        "    texts=df['context'],\n",
        "    labels=df['label'],\n",
        "    test_size=0.2  # 20% for testing\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Japanese summary\n",
        "print(result.summary_jp())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get results as dictionary (for APIs)\n",
        "result.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Random Forest\n",
        "\n",
        "You can also use Random Forest classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Random Forest classifier\n",
        "clf_rf = JapaneseTextClassifier(\n",
        "    class_names=['Real', 'Fake'],\n",
        "    classifier_type='random_forest',\n",
        "    n_estimators=100,  # Number of trees\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train\n",
        "result_rf = clf_rf.train(df['context'], df['label'])\n",
        "print(f\"Random Forest Accuracy: {result_rf.accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Making Predictions with Explanations\n",
        "\n",
        "The key feature is generating human-readable explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample text to classify\n",
        "test_text = \"\"\"\n",
        "政府は本日、新たな経済政策を発表しました。\n",
        "この政策は来年度から実施される予定です。\n",
        "専門家の多くはこの政策を歓迎しています。\n",
        "\"\"\"\n",
        "\n",
        "# Predict with explanation\n",
        "pred = clf.predict(\n",
        "    test_text,\n",
        "    explain=True,       # Generate LIME explanation\n",
        "    num_features=10,    # Top 10 words in explanation\n",
        "    num_samples=500     # LIME perturbation samples\n",
        ")\n",
        "\n",
        "print(f\"Predicted class: {pred.predicted_class}\")\n",
        "print(f\"Confidence: {pred.confidence:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Japanese summary (main feature!)\n",
        "print(\"=\" * 60)\n",
        "print(\"日本語の説明:\")\n",
        "print(\"=\" * 60)\n",
        "print(pred.summary_jp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# English summary\n",
        "print(\"=\" * 60)\n",
        "print(\"English Explanation:\")\n",
        "print(\"=\" * 60)\n",
        "print(pred.summary_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access word weights directly\n",
        "print(\"\\nTop words influencing the prediction:\")\n",
        "for word, weight in pred.explanation.word_weights:\n",
        "    direction = \"↑\" if weight > 0 else \"↓\"\n",
        "    print(f\"  {direction} {word}: {weight:+.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Words that increase probability\n",
        "print(\"\\nWords increasing probability:\")\n",
        "for word, weight in pred.explanation.top_positive_words[:5]:\n",
        "    print(f\"  + {word}: {weight:+.4f}\")\n",
        "\n",
        "# Words that decrease probability\n",
        "print(\"\\nWords decreasing probability:\")\n",
        "for word, weight in pred.explanation.top_negative_words[:5]:\n",
        "    print(f\"  - {word}: {weight:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict multiple texts at once\n",
        "texts = [\n",
        "    \"政府が新しい政策を発表しました。\",\n",
        "    \"この情報は信頼できません。\",\n",
        "    \"専門家がコメントしています。\"\n",
        "]\n",
        "\n",
        "results = clf.predict_batch(texts, explain=False)  # Fast batch without explanation\n",
        "\n",
        "for text, result in zip(texts, results):\n",
        "    print(f\"{text[:20]}... -> {result.predicted_class} ({result.confidence:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Saving and Loading Models\n",
        "\n",
        "Trained models can be saved and loaded for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "clf.save('my_classifier.pkl')\n",
        "print(\"Model saved to 'my_classifier.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "loaded_clf = JapaneseTextClassifier.load('my_classifier.pkl')\n",
        "print(f\"Model loaded: {loaded_clf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the loaded model\n",
        "pred = loaded_clf.predict(\"テスト文章です\", explain=True)\n",
        "print(pred.summary_jp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up\n",
        "import os\n",
        "os.remove('my_classifier.pkl')\n",
        "print(\"Cleaned up model file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. API Integration (FastAPI/htmx)\n",
        "\n",
        "The result classes are designed for easy integration with FastAPI and htmx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results are JSON-serializable\n",
        "pred = clf.predict(\"テスト文章\", explain=True)\n",
        "\n",
        "# Convert to dictionary for API response\n",
        "api_response = pred.to_dict()\n",
        "\n",
        "print(\"API Response (JSON-ready):\")\n",
        "print(f\"Keys: {list(api_response.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the full response\n",
        "import json\n",
        "print(json.dumps(api_response, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HTML output for htmx\n",
        "html = pred.to_html(lang='jp')\n",
        "print(\"HTML output (first 500 chars):\")\n",
        "print(html[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example FastAPI Integration\n",
        "\n",
        "Here's how you would use this with FastAPI:\n",
        "\n",
        "```python\n",
        "from fastapi import FastAPI\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "from tokusan import JapaneseTextClassifier\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load model at startup\n",
        "classifier = JapaneseTextClassifier.load(\"model.pkl\")\n",
        "\n",
        "class PredictRequest(BaseModel):\n",
        "    text: str\n",
        "    explain: bool = True\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(request: PredictRequest):\n",
        "    \"\"\"Return JSON response for API clients.\"\"\"\n",
        "    result = classifier.predict(request.text, explain=request.explain)\n",
        "    return result.to_dict()\n",
        "\n",
        "@app.post(\"/predict/html\", response_class=HTMLResponse)\n",
        "async def predict_html(request: PredictRequest):\n",
        "    \"\"\"Return HTML fragment for htmx.\"\"\"\n",
        "    result = classifier.predict(request.text, explain=request.explain)\n",
        "    return result.to_html(lang='jp')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Quick Reference\n",
        "\n",
        "```python\n",
        "from tokusan import JapaneseTextClassifier\n",
        "\n",
        "# Create and train\n",
        "clf = JapaneseTextClassifier(class_names=['Real', 'Fake'])\n",
        "result = clf.train(texts, labels)\n",
        "\n",
        "# Predict with explanation\n",
        "pred = clf.predict(text, explain=True)\n",
        "print(pred.summary_jp)  # Japanese explanation\n",
        "print(pred.to_dict())   # For API\n",
        "\n",
        "# Save/load\n",
        "clf.save('model.pkl')\n",
        "clf = JapaneseTextClassifier.load('model.pkl')\n",
        "```\n",
        "\n",
        "### Key Classes\n",
        "\n",
        "| Class | Description |\n",
        "|-------|-------------|\n",
        "| `JapaneseTextClassifier` | Main classifier with train/predict/explain |\n",
        "| `TrainingResult` | Training metrics and summary |\n",
        "| `PredictionResult` | Prediction with probabilities and explanation |\n",
        "| `ExplanationResult` | Word weights and Japanese/English summaries |\n",
        "\n",
        "### Key Methods\n",
        "\n",
        "| Method | Description |\n",
        "|--------|-------------|\n",
        "| `clf.train(texts, labels)` | Train the classifier |\n",
        "| `clf.predict(text, explain=True)` | Predict with explanation |\n",
        "| `clf.predict_batch(texts)` | Batch predictions |\n",
        "| `clf.save(path)` / `clf.load(path)` | Save/load model |\n",
        "| `result.summary_jp` | Japanese summary |\n",
        "| `result.to_dict()` | JSON-serializable dict |\n",
        "| `result.to_html()` | HTML for htmx |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
