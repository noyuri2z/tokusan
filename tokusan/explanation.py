"""
Explanation class and domain mapping utilities for tokusan.

This module provides the core classes for representing and visualizing
LIME explanations. The Explanation class stores the results of the
explanation algorithm, while DomainMapper handles the mapping between
internal feature IDs and human-readable representations.

For text classification, the domain mapper converts numeric feature IDs
back to the original words, making explanations interpretable.

Example:
    >>> exp = explainer.explain_instance(text, classifier_fn)
    >>> # Get explanation as a list of (word, weight) tuples
    >>> word_weights = exp.as_list(label=1)
    >>> for word, weight in word_weights:
    ...     print(f"'{word}': {weight:.3f}")
"""

import json
import string
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
from sklearn.utils import check_random_state

from .exceptions import ExplanationError


def _generate_random_id(size: int = 15, random_state=None) -> str:
    """
    Generate a random alphanumeric ID string.

    This helper function creates random div IDs for embedding HTML
    explanations into Jupyter notebooks or web pages.

    Args:
        size: Length of the generated ID string.
        random_state: Random state for reproducible ID generation.

    Returns:
        str: A random string of uppercase letters and digits.
    """
    chars = list(string.ascii_uppercase + string.digits)
    return ''.join(random_state.choice(chars, size, replace=True))


class DomainMapper:
    """
    Abstract base class for mapping feature IDs to domain-specific names.

    Different data types (text, images, tables) require different ways of
    representing features. This base class defines the interface that
    subclasses must implement to provide meaningful feature names.

    For text data, feature IDs map to words. For images, they might map
    to superpixel regions. This abstraction allows the Explanation class
    to work uniformly across different data types.

    Subclasses should override:
        - map_exp_ids(): Convert feature IDs to human-readable names
        - visualize_instance_html(): Generate HTML visualization
    """

    def __init__(self):
        """Initialize the domain mapper."""
        pass

    def map_exp_ids(
        self,
        exp: List[Tuple[int, float]],
        **kwargs
    ) -> List[Tuple[Any, float]]:
        """
        Map feature IDs to human-readable names.

        The default implementation returns the input unchanged.
        Subclasses should override this to provide meaningful mappings.

        Args:
            exp: List of (feature_id, weight) tuples from the explanation.
            **kwargs: Additional arguments for subclass implementations.

        Returns:
            List of (name, weight) tuples with human-readable feature names.
        """
        return exp

    def visualize_instance_html(
        self,
        exp: List[Tuple[int, float]],
        label: int,
        div_name: str,
        exp_object_name: str,
        **kwargs
    ) -> str:
        """
        Generate HTML/JavaScript for visualizing the explained instance.

        The default implementation returns an empty string.
        Subclasses should override this to provide visual representations.

        Args:
            exp: List of (feature_id, weight) tuples.
            label: The class label being explained.
            div_name: Name of the HTML div element for rendering.
            exp_object_name: Name of the JavaScript explanation object.
            **kwargs: Additional visualization options.

        Returns:
            str: JavaScript code for visualization, or empty string.
        """
        return ''


class Explanation:
    """
    Container for LIME explanation results.

    This class stores all the information generated by the LIME algorithm
    when explaining a prediction. It provides methods to access explanations
    in different formats (lists, maps, plots) and to visualize results.

    Attributes:
        mode: Either 'classification' or 'regression'.
        domain_mapper: DomainMapper instance for feature name mapping.
        local_exp: Dictionary mapping label indices to feature explanations.
        intercept: Dictionary mapping labels to intercept values.
        score: Dictionary mapping labels to R^2 scores of local model.
        local_pred: Dictionary mapping labels to local model predictions.
        class_names: List of class names (for classification).
        predict_proba: Prediction probabilities (for classification).
        top_labels: List of top predicted labels.

    Example:
        >>> exp = explainer.explain_instance(text, classifier_fn)
        >>> # Get the predicted probabilities
        >>> print(exp.predict_proba)
        >>> # Get explanation for class 1
        >>> features = exp.as_list(label=1)
    """

    def __init__(
        self,
        domain_mapper: DomainMapper,
        mode: str = 'classification',
        class_names: Optional[List[str]] = None,
        random_state=None
    ):
        """
        Initialize an Explanation object.

        Args:
            domain_mapper: DomainMapper instance for converting feature IDs
                          to human-readable names.
            mode: Either 'classification' or 'regression'.
            class_names: List of class names for classification tasks.
                        If None, classes will be named '0', '1', etc.
            random_state: Random state for reproducible visualizations.

        Raises:
            ExplanationError: If mode is not 'classification' or 'regression'.
        """
        self.random_state = random_state
        self.mode = mode
        self.domain_mapper = domain_mapper

        # Dictionaries to store explanation data for each label
        self.local_exp: Dict[int, List[Tuple[int, float]]] = {}
        self.intercept: Dict[int, float] = {}
        self.score: Dict[int, float] = {}
        self.local_pred: Dict[int, float] = {}

        if mode == 'classification':
            self.class_names = class_names
            self.top_labels: Optional[List[int]] = None
            self.predict_proba: Optional[np.ndarray] = None
        elif mode == 'regression':
            self.class_names = ['negative', 'positive']
            self.predicted_value: Optional[float] = None
            self.min_value: float = 0.0
            self.max_value: float = 1.0
            self.dummy_label: int = 1
        else:
            raise ExplanationError(
                f'Invalid explanation mode "{mode}". '
                'Should be either "classification" or "regression".'
            )

    def available_labels(self) -> List[int]:
        """
        Get the list of labels for which explanations are available.

        Returns:
            List[int]: Label indices with computed explanations.

        Raises:
            NotImplementedError: If called on a regression explanation.
        """
        if self.mode != "classification":
            raise NotImplementedError(
                'Not supported for regression explanations.'
            )

        if self.top_labels:
            return list(self.top_labels)
        return list(self.local_exp.keys())

    def as_list(
        self,
        label: int = 1,
        **kwargs
    ) -> List[Tuple[str, float]]:
        """
        Get the explanation as a list of (feature_name, weight) tuples.

        This is the most common way to access explanation results.
        Features are mapped to human-readable names using the domain mapper.

        Args:
            label: The label index to get explanations for.
                  Ignored for regression explanations.
            **kwargs: Additional arguments passed to the domain mapper.

        Returns:
            List of (feature_name, weight) tuples, where higher absolute
            weight indicates greater influence on the prediction.

        Example:
            >>> exp = explainer.explain_instance(text, classifier_fn)
            >>> for word, weight in exp.as_list(label=1):
            ...     direction = "increases" if weight > 0 else "decreases"
            ...     print(f"'{word}' {direction} probability")
        """
        label_to_use = label if self.mode == "classification" else self.dummy_label
        mapped_exp = self.domain_mapper.map_exp_ids(
            self.local_exp[label_to_use], **kwargs
        )
        # Ensure weights are Python floats for JSON serialization
        return [(x[0], float(x[1])) for x in mapped_exp]

    def as_map(self) -> Dict[int, List[Tuple[int, float]]]:
        """
        Get the raw explanation map.

        Returns:
            Dictionary mapping label indices to lists of
            (feature_id, weight) tuples.
        """
        return self.local_exp

    def as_pyplot_figure(
        self,
        label: int = 1,
        figsize: Tuple[int, int] = (4, 4),
        **kwargs
    ):
        """
        Create a matplotlib bar chart of feature importances.

        Args:
            label: Label index to visualize. Ignored for regression.
            figsize: Figure size as (width, height) tuple.
            **kwargs: Additional arguments passed to the domain mapper.

        Returns:
            matplotlib.figure.Figure: Bar chart showing feature weights.

        Raises:
            ImportError: If matplotlib is not installed.

        Example:
            >>> fig = exp.as_pyplot_figure(label=1)
            >>> fig.savefig('explanation.png')
        """
        import matplotlib.pyplot as plt

        exp = self.as_list(label=label, **kwargs)
        fig = plt.figure(figsize=figsize)

        # Extract values and names, reversing for top-to-bottom display
        vals = [x[1] for x in exp]
        names = [x[0] for x in exp]
        vals.reverse()
        names.reverse()

        # Color bars based on positive/negative contribution
        colors = ['green' if x > 0 else 'red' for x in vals]
        pos = np.arange(len(exp)) + 0.5

        plt.barh(pos, vals, align='center', color=colors)
        plt.yticks(pos, names)

        # Set appropriate title based on mode
        if self.mode == "classification":
            title = f'Local explanation for class {self.class_names[label]}'
        else:
            title = 'Local explanation'
        plt.title(title)

        return fig

    def show_in_notebook(
        self,
        labels: Optional[List[int]] = None,
        predict_proba: bool = True,
        show_predicted_value: bool = True,
        **kwargs
    ):
        """
        Display the explanation in a Jupyter notebook.

        Args:
            labels: List of label indices to show. If None, shows all.
            predict_proba: Whether to show prediction probabilities.
            show_predicted_value: Whether to show predicted value (regression).
            **kwargs: Additional arguments passed to as_html().

        Raises:
            ImportError: If IPython is not installed.
        """
        from IPython.core.display import display, HTML
        display(HTML(self.as_html(
            labels=labels,
            predict_proba=predict_proba,
            show_predicted_value=show_predicted_value,
            **kwargs
        )))

    def save_to_file(
        self,
        file_path: str,
        labels: Optional[List[int]] = None,
        predict_proba: bool = True,
        show_predicted_value: bool = True,
        **kwargs
    ):
        """
        Save the explanation as an HTML file.

        Args:
            file_path: Path to save the HTML file.
            labels: List of label indices to include. If None, includes all.
            predict_proba: Whether to include prediction probabilities.
            show_predicted_value: Whether to include predicted value.
            **kwargs: Additional arguments passed to as_html().
        """
        with open(file_path, 'w', encoding='utf8') as file:
            file.write(self.as_html(
                labels=labels,
                predict_proba=predict_proba,
                show_predicted_value=show_predicted_value,
                **kwargs
            ))

    def as_html(
        self,
        labels: Optional[List[int]] = None,
        predict_proba: bool = True,
        show_predicted_value: bool = True,
        **kwargs
    ) -> str:
        """
        Generate an HTML representation of the explanation.

        Creates a self-contained HTML page with JavaScript visualizations
        showing feature importances and prediction probabilities.

        Args:
            labels: List of label indices to include. If None, includes all.
            predict_proba: Whether to show prediction probability bar chart.
            show_predicted_value: Whether to show regression predicted value.
            **kwargs: Additional arguments passed to domain mapper.

        Returns:
            str: Complete HTML page as a string.
        """
        def jsonize(x):
            return json.dumps(x, ensure_ascii=False)

        if labels is None and self.mode == "classification":
            labels = self.available_labels()

        # Generate random ID for div elements
        random_state = check_random_state(self.random_state)
        random_id = _generate_random_id(size=15, random_state=random_state)

        # Build HTML structure
        out = '''<html>
        <meta http-equiv="content-type" content="text/html; charset=UTF8">
        <head></head><body>'''
        out += f'''
        <div class="tokusan top_div" id="top_div{random_id}"></div>
        '''

        # Build prediction probability visualization (classification only)
        predict_proba_js = ''
        if self.mode == "classification" and predict_proba and self.predict_proba is not None:
            class_names_json = jsonize([str(x) for x in self.class_names])
            proba_json = jsonize(list(self.predict_proba.astype(float)))
            predict_proba_js = f'''
            var pp_div = top_div.append('div').classed('tokusan predict_proba', true);
            var pp_text = pp_div.append('p').text('Prediction probabilities: {proba_json}');
            '''

        # Build explanation visualization
        exp_js = f'''var exp_div;'''

        if self.mode == "classification":
            for label in labels:
                exp_data = jsonize(self.as_list(label))
                exp_js += f'''
                exp_div = top_div.append('div').classed('tokusan explanation', true);
                exp_div.append('h3').text('Class: {self.class_names[label]}');
                exp_div.append('pre').text({exp_data});
                '''
        else:
            exp_data = jsonize(self.as_list())
            exp_js += f'''
            exp_div = top_div.append('div').classed('tokusan explanation', true);
            exp_div.append('pre').text({exp_data});
            '''

        out += f'''
        <script>
        var top_div = document.getElementById('top_div{random_id}');
        top_div.innerHTML = '';
        {predict_proba_js}
        {exp_js}
        </script>
        '''
        out += '</body></html>'

        return out
